#!/usr/bin/env python3
"""
AutoGluon 1.0 Setup and Environment Check
AutoGluon 1.0ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ»ç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆ

æ©Ÿèƒ½:
- AutoGluon 1.0ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
- A100 GPUç¢ºèª
- ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
- ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±è¡¨ç¤º
"""

import subprocess
import sys
import os
import platform
import psutil

def run_command(command, description):
    """
    ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œãƒ˜ãƒ«ãƒ‘ãƒ¼
    """
    print(f"ğŸ”§ {description}...")
    try:
        result = subprocess.run(command, shell=True, capture_output=True, text=True)
        if result.returncode == 0:
            print(f"âœ… {description}å®Œäº†")
            return True
        else:
            print(f"âŒ {description}å¤±æ•—: {result.stderr}")
            return False
    except Exception as e:
        print(f"âŒ {description}ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def check_system_info():
    """
    ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ç¢ºèª
    """
    print("ğŸ’» ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±:")
    print(f"   ğŸ Python: {sys.version}")
    print(f"   ğŸ’¾ OS: {platform.system()} {platform.release()}")
    print(f"   ğŸ–¥ï¸  CPU: {psutil.cpu_count()}ã‚³ã‚¢")
    print(f"   ğŸ§  RAM: {psutil.virtual_memory().total // (1024**3)}GB")

def check_gpu():
    """
    GPUç¢ºèª
    """
    print("\nğŸ”¥ GPUç¢ºèª:")
    try:
        import torch
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            print(f"   âœ… GPUæ¤œå‡º: {gpu_count}åŸº")
            
            for i in range(gpu_count):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_memory = torch.cuda.get_device_properties(i).total_memory // (1024**3)
                print(f"   ğŸš€ GPU {i}: {gpu_name} ({gpu_memory}GB)")
                
            # A100ç¢ºèª
            if "A100" in gpu_name:
                print("   ğŸ¯ A100æ¤œå‡º! æœ€é«˜æ€§èƒ½ã§å®Ÿè¡Œå¯èƒ½")
            return True
        else:
            print("   âš ï¸  GPUæœªæ¤œå‡ºã€CPUå®Ÿè¡Œã¨ãªã‚Šã¾ã™")
            return False
    except ImportError:
        print("   âŒ PyTorchæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")
        return False

def install_dependencies():
    """
    ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
    """
    print("\nğŸ“¦ AutoGluon 1.0ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«:")
    
    # requirements_autogluon.txtã‹ã‚‰èª­ã¿è¾¼ã¿
    if os.path.exists('requirements_autogluon.txt'):
        success = run_command(
            f"{sys.executable} -m pip install -r requirements_autogluon.txt",
            "AutoGluon 1.0ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
        )
        if not success:
            print("âŒ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¤±æ•—")
            return False
    else:
        print("âŒ requirements_autogluon.txtæœªç™ºè¦‹")
        # ç›´æ¥ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
        packages = [
            "autogluon>=1.0.0",
            "pandas>=2.0",
            "numpy>=1.21",
            "scikit-learn>=1.3",
            "torch>=2.0",
            "psutil>=5.8.0",
            "tqdm>=4.64.0"
        ]
        
        for package in packages:
            success = run_command(
                f"{sys.executable} -m pip install '{package}'",
                f"{package}ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
            )
            if not success:
                print(f"âŒ {package}ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¤±æ•—")
                return False
    
    return True

def verify_autogluon():
    """
    AutoGluon 1.0å‹•ä½œç¢ºèª
    """
    print("\nğŸ§ª AutoGluon 1.0å‹•ä½œç¢ºèª:")
    try:
        from autogluon.tabular import TabularPredictor
        import autogluon
        
        version = autogluon.__version__
        print(f"   âœ… AutoGluon {version}ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿")
        
        # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª
        if version.startswith('1.'):
            print("   ğŸ‰ AutoGluon 1.0ç³»ç¢ºèª!")
            return True
        else:
            print(f"   âš ï¸  AutoGluon {version}æ¤œå‡ºã€1.0ç³»æ¨å¥¨")
            return False
            
    except ImportError as e:
        print(f"   âŒ AutoGluonã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False

def check_data_files():
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
    """
    print("\nğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª:")
    
    required_files = [
        'data/train.tsv',
        'data/test.tsv'
    ]
    
    all_present = True
    for file_path in required_files:
        if os.path.exists(file_path):
            size_mb = os.path.getsize(file_path) / (1024 * 1024)
            print(f"   âœ… {file_path} ({size_mb:.1f}MB)")
        else:
            print(f"   âŒ {file_path} æœªç™ºè¦‹")
            all_present = False
    
    return all_present

def main():
    """
    ãƒ¡ã‚¤ãƒ³ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å‡¦ç†
    """
    print("=" * 60)
    print("ğŸš€ AutoGluon 1.0 Setup & Environment Check")
    print("ğŸ“Š OpenML Benchmark 1ä½ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒæ§‹ç¯‰")
    print("=" * 60)
    
    # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ç¢ºèª
    check_system_info()
    
    # GPUç¢ºèª
    gpu_available = check_gpu()
    
    # ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
    deps_success = install_dependencies()
    
    if deps_success:
        # AutoGluonå‹•ä½œç¢ºèª
        autogluon_ok = verify_autogluon()
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª  
        data_ok = check_data_files()
        
        print("\n" + "=" * 60)
        print("ğŸ“‹ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—çµæœ:")
        print(f"   ğŸ”§ ä¾å­˜é–¢ä¿‚: {'âœ…' if deps_success else 'âŒ'}")
        print(f"   ğŸ AutoGluon 1.0: {'âœ…' if autogluon_ok else 'âŒ'}")
        print(f"   ğŸ”¥ GPU: {'âœ…' if gpu_available else 'âš ï¸ CPU'}")
        print(f"   ğŸ“‚ ãƒ‡ãƒ¼ã‚¿: {'âœ…' if data_ok else 'âŒ'}")
        
        if all([deps_success, autogluon_ok, data_ok]):
            print("\nğŸ‰ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†!")
            print("ğŸ’¡ å®Ÿè¡Œæº–å‚™å®Œäº†:")
            print("   python autogluon_1_0_implementation.py")
        else:
            print("\nâš ï¸  ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã«å•é¡ŒãŒã‚ã‚Šã¾ã™")
            if not data_ok:
                print("ğŸ’¡ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’data/ãƒ•ã‚©ãƒ«ãƒ€ã«é…ç½®ã—ã¦ãã ã•ã„")
    else:
        print("\nâŒ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å¤±æ•—")
    
    print("=" * 60)

if __name__ == "__main__":
    main() 